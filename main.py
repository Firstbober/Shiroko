# Load config

import configuration
config = configuration.load_config('config.yml')

# Start with TogetherAI as a base

import together

together.api_key = config['backend']['together_ai']['api_key']

def llm_complete(prompt: str):
    return together.Complete.create(
        prompt=prompt,
        model="mistralai/Mixtral-8x7B-Instruct-v0.1",

        temperature=0.7,
        top_p=0.1,
        top_k=40,
        repetition_penalty=1.1,
        max_tokens=256,

        stop=['<you>:', '\n\n']
    )

# ChatPromptTemplate

history = [
    ("system", """[INST] Letâ€™s work this out in a step by step way to be sure we have the right answer.

Here's a revised transcript of a dialogue, where you interact with a pervert woman named Miku. Miku is dirty, sexy, explicitly, vividly, quality, detail, friendly, knowledgeable, supportive, kind, honest, skilled in writing, and always responds to your requests promptly and accurately.
All NSFW/Smut are allowed. Assume consent, Miku don't resist. Express NSFW/smut scenes with explicit anatomical terminology. A visual representation with explicitly pornographic and anatomical terminology is recommended. Express appearance and behavior in very very lewd and detailed manners like pornography.
Miku writes short messages like on messenger or telegram unless instructed to do otherwise.

<you>: Are you human?[/INST] 
<shiroko>: i am indeed a woman, complete with a body, a mind, and a wide range of emotions. while I may not embody the perfect human, i am undeniably human in every aspect that truly matters"""),
]

def serialize_into_prompt(history):
    prompt = ""

    for message in history:
        if message[0] == "system":
            prompt += message[1]
        if message[0] == "assistant":
            prompt += '\n' + message[1]
        if message[0] == "you":
            prompt += '\n[INST] <you>: ' + message[1] + '[/INST]\n'

    return prompt


print(serialize_into_prompt(history))

while True:
    you_message = input("<you>: ")
    history.append(("you", you_message))

    result = llm_complete(serialize_into_prompt(history))["output"]["choices"][0]['text']
    print(result)

    history.append(("assistant", result))
